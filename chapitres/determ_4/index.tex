\chapter{Le déterminant}

%
%
\section{Groupes symétriques}
%
%
%
\subsection{Permutation}
%
\paragraph{Définition} Soit $E$ un ensemble. On appelle permutation de $E$ un bijection  de $E$ dans $D$. On note $Sym(E)$ l'ensemble de permutations de $E$

\paragraph{Définition} On munit $Sym(E)$ de la composition
\begin{eqnarray*}
  \circ: Sym(E) \times Sym(E) &\rightarrow& Sym(E) \\
  (\sigma , \tau) &\mapsto& \sigma \circ \tau
\end{eqnarray*}
Par définition, pour tout $x\in E$
$$(\sigma \circ \tau)(x) = \sigma(\tau(x))$$
La composée de deux bijections étant encore une bijection, la composée de deux permutations de $E$ est encore une permutation de $E$.

%
\subsection{Groupe symétrique}
%
Alors $(Sym(E), \circ)$ est un groupe. En effet
\begin{itemize}
  \item la composition des permutations est associative
    $$\alpha \circ (\beta \circ \gamma) = (\alpha \circ \beta) \circ \gamma ~ \forall \alpha, \beta, \gamma \in Sym(E)$$
  
  \item l'application
    \begin{eqnarray*}
      id_E: E &\rightarrow& E \\
      x &\mapsto& id_E(x) = x 
    \end{eqnarray*}
    est une permutation de $E$ qui est élément neutre pour $\circ$
    
  \item si $\sigma \in Sym(E)$, alors la permutation inverse de $\sigma$ est la bijection réciproque $\sigma^{-1}: E \rightarrow E$ de $\sigma$
\end{itemize}
On appelle ce groupe le groupe symétrique de $E$.

\paragraph{Remarque} Dans la suite nous nous concentrons sur le cas où $E = \{1; 2; \ldots; n\}$ pour un certain entier naturel $n\geq 1$. On note alors
$$S_n = Sym(\{1; 2; \ldots; n\})$$
Si $\sigma \in S_n$, on pourra écrire
$$\sigma = \begin{pmatrix} 1 & 2 & \ldots & n \\ \sigma(1) & \sigma(2) & \ldots & \sigma(n) \end{pmatrix}$$

%
\subsection{Support}
%
\paragraph{Définition} Pour tout $\sigma \in S_n$, on appelle support de $\sigma$ et on note $supp(\sigma)$ l'ensemble
$$supp(\sigma) = \{i \in \{1; 2; \ldots; n\} \vert \sigma(i) \neq i\}$$

%
\subsection{Cycle}
%
\paragraph{Définition} Soit $n \geq 1$ un entier naturel et soit $k \in \{1; 2; \ldots; n\}$. On dit qu'une permutation $\sigma \in S_n$ est un cycle de longeur $k$ ou $k$-cycle, s'il existe $i_1, i_2, \ldots, i_k \in  \{1; 2; \ldots; n\}$ tels que
$$\sigma(i_1) = i_2 \rightarrow \sigma(i_2) = i_3 \rightarrow \ldots \rightarrow \sigma(i_{k-1}) = i_k \rightarrow \sigma(i_k) = i_1$$
et $\sigma(i) = i$ si $i \notin \{i_1; i_2; \ldots; i_k\}$

\paragraph{Remarque} L'ensemble $\{i_1; i_2; \ldots; i_k\}$ est le support du $k$-cycle.

\paragraph{Notation} Soit $\sigma$ un $k$-cycle, on note $\sigma = (i_1 ~ i_2 ~ \ldots ~ i_k)$


%
\subsection{Transposition}
%
\paragraph{Définition} Les 2-cycles de $S_n$ s'appellent les transpositions de $S_n$

\paragraph{Proposition} Soit $m \geq 2$ un entier naturel. Alors toute permutation de $S_n$ peut s'écrire comme composée de transpositions.

\paragraph{Démonstration}  On raisonne par récurence sur le cardinal\footnote{Le cardinal d'un ensemble fini est le nombre de ses éléments.} de $supp(\sigma)$.
\subparagraph{Annonce de la récurence} Soit $\sigma \in S_n$ telle que $supp(\sigma)$ soit de cardinal égal à $0$. Donc $supp(\sigma)$ est vide (on note $supp(\sigma) = \emptyset$). Autrement dit, $\sigma$ fixe tous les éléments de $\{1; 2; \ldots; n\}$. Par conséquent, $\sigma = id$. \\
On peut écrire $\sigma = id = (1 ~ 2)\circ(1 ~ 2)$, ce qui est une écriture de $\sigma$ comme composée de transpositions.

\subparagraph{Hypothése de récurence} Soit $k \in \{1; 2; \ldots; n\}$. On suppose que pour tout $\tau \in S_n$, telle que $card(supp(\tau)) \leq k-1$, $\tau$ s'écrit comme composée de transposition.

\subparagraph{Pas de récurence} Soit $\sigma \in S_n$ telle que le cardinal de $supp(\sigma)$ soit égal à $k$.
$$supp(\sigma) = \{i_1; i_2; \ldots; i_k\} \text{ avec } 1 \leq i_1 \leq i_2 \leq \ldots \leq i_k \leq n$$
On forme la permutation $\tau = (i_k ~ \sigma(i_k)) \circ \sigma$. La permutation $\tau$ a un support de cardinal $< k$. En effet, on verifie que $supp(\tau)$ est contenue dans $supp(\sigma)$. Or on a
$$\tau(i_k) = (i_k ~ \sigma(i_k)) \circ \sigma) (i_k) = (i_k ~ \sigma(i_k))(\sigma(i_k)) = i_k$$
Donc $supp(\tau)$ est contenue dans $\{i_1; i_2; \ldots; i_k-1\}$, donc est de cardinal $\leq k-1 < k$. Par hypothèse de récurence, $\tau$ s'écrit comme composée de transpositions
$$\tau = \tau_1 \circ \tau_2 \circ \ldots \circ \tau_n$$
On en déduit que 
\begin{eqnarray*}
  \sigma &=& (i_k ~ \sigma(i_k))^{-1} \circ \tau \\
    &=& (i_k ~ \sigma(i_k)) \circ \tau_1 \circ \tau_2 \circ \ldots \circ \tau_n
\end{eqnarray*}
\\
Par principe de récurence, la propriété est vraie pour toute permutation de $S_n$.

\paragraph{Proposition} Soit $n \geq 1$ un entier naturel. Alors $S_n$ est de cardinal $n! = 1 \cdot 2 \cdot \ldots \cdot n$.

\paragraph{Démonstration} Pour construire une permutation $\sigma$ de $S_n$,
\begin{itemize}
  \item on choisit l'image $\sigma(1)$ de $1$ pour $\sigma$, il y a $n$ choix possibles.
  \item puis on choisit $\sigma(2)$ qui est l'image de $2$ par $\sigma$, il y a $n-1$ choix possile dans $\{1; 2; \ldots; n\} \backslash \{\sigma(1)\}$.
  \item puis on choisit $\sigma(3)$; il y a $n-1$ choix possibles dans $\{1; 2; \ldots; n\} \backslash \{\sigma(1); \sigma(2)\}$.
  \item ainsi de suite
\end{itemize}
Par conséquent, le nombre de permutations que l'on peut construire est 
$$n \cdot (n-1) \cdot \ldots \cdot 2 \cdot 1 = n!$$

\paragraph{Exemple} Décrivons $S_2$ et $S_3$
\begin{itemize}
  \item $S_2$ est de cardinal $2! = 2$. On a 
    $$S_2 = \{id; (1 ~ 2)\}$$
  \item $S_3$ est de cardinal $3! = 6$. On a
    $$S_3 = \{id; (1 ~ 2); (1 ~ 3); (2 ~ 3); (1 ~ 2 ~ 3); (1 ~ 3 ~ 2)\}$$
\end{itemize}

%
\subsection{Inversion de paire}
%
\paragraph{Définition} Soient $i, j \in \{1; 2; \ldots; n\}$, $i < j$, et $\sigma \in S_n$. On dit que $\sigma$ présente une inversion en la paire $(i, j)$ si 
$$\sigma(i) > \sigma(j)$$

%
\subsection{Permutation paire}
%
\paragraph{Définition} Soit $\sigma \in S_n$. On dit que $\sigma$ est une permutation paire si elle présente un nombre paire d'inversions, et une permutation impaire sinon.

%
\subsection{Signature}
%
\paragraph{Définition} On appelle signature de $\sigma$, et on note $\epsilon(\sigma)$ le nombre
$$\epsilon(\sigma) \left\{ \begin{array}{lr} 
  1 & \text{si } \sigma \text{ est une permutation paire} \\ 
  -1 & \text{si } \sigma \text{ est une permutation impaire} 
\end{array} \right.$$
Autrement dit, si $n_{\sigma}$ est le nombre d'inversions de $\sigma$ on a
$$\epsilon(\sigma) = (-1)^{n_{\sigma}} \in \{-1; 1\}$$

\paragraph{Exemple}
$$\sigma = \begin{pmatrix} 1 & 2 & 3 & 4 & 5 \\ 3 & 1 & 5 & 2 & 4 \end{pmatrix} \in S_5$$
Paires d'inversions
$$(1, 2), (1, 4), (3, 4), (3, 5)$$
$\sigma$ presente $4$ inversion, $\sigma$ est donc paire et $\epsilon(\sigma) = 1$

\paragraph{Théorème} Soient $\sigma, \tau \in S_n$. Alors
$$\epsilon(\sigma \circ \tau) = \epsilon(\sigma) \cdot \epsilon(\tau)$$

%
%
\section{Déterminant}
%
%

%
\subsection{Produit élémentaire}
%
\paragraph{Définition} Soit $A = (a_{ij})$ une matrice carrée de taille $n\times n$. Soit $\sigma in S_n$. On appelle produit élémentaire associé à $\sigma$ le nombre
$$a_{\sigma(1) 1} \cdot a_{\sigma(2) 2} \cdot \ldots \cdot a_{\sigma(n) n} = \prod_{i=1}^{n} a_{\sigma(i) i}$$
%
\subsection{Produit signé}
%
\paragraph{Définition} On appelle produit signé associé à $\sigma$ le nombre 
$$p_{\sigma}(A) = \epsilon(\sigma) \cdot a_{\sigma(1) 1} \cdot a_{\sigma(2) 2} \cdot \ldots \cdot a_{\sigma(n) n} = \epsilon(\sigma) \prod_{i=1}^{n} a_{\sigma(i) i}$$

%
\subsection{Déterminant}
%
\paragraph{Définition} Soit $A = (a_{ij})_{1 \leq i, j \leq n}$ une matrice carrée de taille $n \times n$. On appelle déterminant de $A$ le nombre
$$det(A) = \sum_{\sigma \in S_n} p_{\sigma}(A) = \sum_{\sigma \in S_n} \epsilon(\sigma) \prod_{i=1}^{n} a_{\sigma(i) i}$$

\paragraph{Exemple} Soit $A = \begin{pmatrix} 1 & 2 & 3 \\ 0 & 5 & 1 \\ -7 & 4 & -2 \end{pmatrix} \in M_{3}(\R)$.
$$S_3 = \{id; (1 ~ 2); (1 ~ 3); (2 ~ 3); (1 ~ 2 ~ 3); (1 ~ 3 ~ 2)\}$$
On a 
\begin{eqnarray*}
  \sigma = id           &\Rightarrow& p_{\sigma}(A) = 1 \cdot A_{11} \cdot A_{22} \cdot A_{33} \\
  \sigma = (1 ~ 2)      &\Rightarrow& p_{\sigma}(A) = 1 \cdot A_{21} \cdot A_{21} \cdot A_{33} \\
  \sigma = (1 ~ 3)      &\Rightarrow& p_{\sigma}(A) = 1 \cdot A_{31} \cdot A_{22} \cdot A_{13} \\
  \sigma = (2 ~ 3)      &\Rightarrow& p_{\sigma}(A) = 1 \cdot A_{11} \cdot A_{32} \cdot A_{23} \\
  \sigma = (1 ~ 2 ~ 3)  &\Rightarrow& p_{\sigma}(A) = 1 \cdot A_{21} \cdot A_{32} \cdot A_{13} \\
  \sigma = (1 ~ 3 ~ 2)  &\Rightarrow& p_{\sigma}(A) = 1 \cdot A_{31} \cdot A_{12} \cdot A_{23}
\end{eqnarray*}

\paragraph{Notation} Si $A = (a_{ij})_{1 \leq i, j\leq n}$ est une matrice carrée de taille $n\times n$ on note
$$\vert a_{ij} \vert _{1 \leq i, j \leq n} = det(A)$$

%
\subsection{Déterminant d'un système des matrices colonnes}
%
\paragraph{Définition} On peut aussi parler du déterminant d'un système de $n$ matrices colonnes $m$-lignes
$$C_1, C_2, \ldots, C_n  \in M_{n\times 1}(\R)$$
Suivant
$$C_{j} = \begin{pmatrix} c_{1j} \\ c_{2j} \\ \vdots \\ c_{nj} \end{pmatrix} \text{ pour tout } j \in \{1; \ldots ; n\}$$
on définit le déterminant du système $(C_1, C_2, \ldots, C_n)$ par
$$det(C_1, C_2, \ldots, C_n) = \sum_{\sigma \in S_n} \epsilon(\sigma) \cdot c_{\sigma(1) 1} \cdot \ldots \cdot c_{\sigma(n) n} \in \R$$
Si $C$ est la matrice de taille $n \times n$ dont les colonnes sont les $C_j$, $C = (C_1, C_2, \ldots, C_n)$ alors on a
$$det(C_1, C_2, \ldots, C_n) = det(C)$$
\paragraph{Remarque} Le point de vue adopté, matrice ou système de matrices colonnes sera clair d'après la notation et le contexte.

\paragraph{Théorème} Soit $n\geq 1$ un entier naturel. Alors l'application $n$ fois
\begin{eqnarray*}
  det: M_{n\times 1}(\R) \times M_{n\times 1}(\R) \times \ldots \times M_{n\times 1}(\R) &\rightarrow& \R \\
  (C_1, C_2, \ldots, C_n) &\mapsto& det(C_1, C_2, \ldots, C_n)
\end{eqnarray*}
posséde les propriétés suivantes
\begin{enumerate}
  \item Pour tout $j \in \{1; \ldots; n \}$, pour tous $C_1, \ldots, C_j, C_j', \ldots, C_n \in M_{n\times 1}(\R)$
    \begin{eqnarray*}
      det(C_1, \ldots, C_j + C_j', \ldots, C_n) =& det(C_1, \ldots, C_j, \ldots, C_n) \\
        &+ det(C_1, \ldots, C_j', \ldots, C_n)
    \end{eqnarray*}
    
  \item Pour tout $j \in \{1; \ldots; n\}$, pour tous $C_1, C_2, \ldots, C_n \in M_{n\times 1}(\R)$, pour tout $\lambda \in \R$
    $$det(C_1, \ldots, \lambda C_j, \ldots, C_n) = \lambda \cdot det(C_1, \ldots, C_j, \ldots, C_n)$$
    
  \item Pour tous $C_1, C_2, \ldots, C_n \in M_{n\times 1}(\R)$, pour tous $i, j \in \{1; \ldots; n\}, i \neq j$, si $C_i = C_j$, alors
    $$det(C_1, \ldots, C_i, \ldots, C_j(=C_i), \ldots, C_n) = 0$$
\end{enumerate}

\paragraph{Démonstration} 
\begin{enumerate}
  \item On a
    $$det(C_1, \ldots, C_j + C_j', \ldots, C_n) = \sum_{\sigma \in S_n} p_\sigma(C_1, \ldots, C_j + C_j' , \ldots, C_n)$$
    où
    $$ p_{\sigma}(C_1, \ldots, C_j + C_j', \ldots, C_n) = \epsilon(\sigma) \cdot c_{\sigma(1) 1} \cdot \ldots \cdot (c_{\sigma(j) j} + c_{\sigma(j) j}') \cdot \ldots \cdot c_{\sigma(n) n}$$
    $\Rightarrow$ distributivité de $\circ$ par rapport à $+$
   
  \item On a
    $$det(C_1, \ldots, \lambda C_j', \ldots, C_n) = \sum_{\sigma \in S_n} p_\sigma(C_1, \ldots, \lambda C_j' , \ldots, C_n)$$
    où
    $$ p_{\sigma}(C_1, \ldots, \lambda C_j', \ldots, C_n) = \epsilon(\sigma) \cdot c_{\sigma(1) 1} \cdot \ldots \cdot \lambda \cdot c_{\sigma(j) j}  \cdot \ldots \cdot c_{\sigma(n) n}$$

  \item Soit $\tau = (i ~ j) \in S_n$. On regroupe les permutations de $S_n$ par paires comme suit: Chaque $\sigma \in S_n$ avec $\sigma \circ \tau \in S_n$ \\
    On a: si $\sigma = \sigma \circ \tau$ on aurait
    \begin{eqnarray*}
      id = \sigma^{-1} \circ \sigma &=& \sigma^{-1} \circ (\sigma \circ \tau) \\
        &=& (\sigma^{-1} \circ \sigma) \circ \tau \\
        &=& id \circ \tau = \tau \rightarrow\text{ impossibru}
    \end{eqnarray*}
    donc $\sigma \neq \sigma \circ \tau$. On a
    \begin{eqnarray*}
      (\sigma \circ \tau) \circ \tau &=& \sigma \circ (\tau \circ \tau) \\
        &=& \sigma \circ (id) \\
        &=& \sigma 
    \end{eqnarray*}
    %
    On obtien aisni $\frac{n!}{2}$ paires de la forme $\{\sigma; \sigma  \circ \tau\}$. Dans chaque de ces paires on sélectionne une permutation $\sigma_n$ tout, on a donc sélectioné $\frac{n!}{2}$ permutations $\sigma_1, \sigma_2, \ldots, \sigma_{\frac{n!}{2}}$. On a donc
    $$S_n = \{ \sigma_1; \sigma_1 \circ \tau; \sigma_2; \sigma_2 \circ \tau; \ldots; \sigma_{\frac{n!}{2}}; \sigma_{\frac{n!}{2}} \circ \tau \}$$
    On obtient 
    \begin{eqnarray*}
      det(C_1, C_2, \ldots, C_n) &=& \sum_{\sigma \in S_n} p_{\sigma}(C_1, C_2, \ldots, C_n) \\
       &=& \sum_{i=1}^{\frac{n!}{2}} p_{\sigma_i}(C_1, C_2, \ldots, C_n) + p_{\sigma_i \circ \tau}(C_1, C_2, \ldots, C_n)
    \end{eqnarray*}
    %
    Montrons que pour tout $\sigma \in S_n$, on a
    $$p_{\sigma \circ \tau}(C_1, C_2, \ldots, C_n) = -p_{\sigma}(C_1, C_2, \ldots, C_n)$$
    Soit $\sigma \in S_n$. On a 
    $$p_{\sigma \circ \tau}(C_1, C_2, \ldots, C_n) = \epsilon(\sigma \circ \tau) \cdot a_{(\sigma \circ\tau)(1) 1} \cdot a_{(\sigma \circ\tau)(2) 2} \cdot \ldots \cdot a_{(\sigma \circ\tau)(n) n}$$
    Soit $k \in \{1; \ldots; n\}$
    \begin{itemize}
      \item si $k\notin \{i; j\}$, alors $\tau(k) = k$. Par suite 
        $$a_{(\sigma \circ \tau)(k) k} = a_{\sigma(k) k}$$
      
      \item si $k = i$, alors $\tau(k) = j$. Par suite $a_{(\sigma \circ \tau)(k) k} = a_{\sigma(j) i}$. Puisque $C_i = C_j$ on a $a_{\sigma(j) i} = a_{\sigma(j) j}$. On a donc
        $$a_{(\sigma \circ \tau)(k) k} = a_{(\sigma \circ \tau)(i) i} = a_{\sigma(j) j}$$
        
      \item si $k = j$, alors $\tau(k) = i$. Par suite $a_{(\sigma \circ \tau)(k) k} = a_{\sigma(i) j}$. Puisque $C_j = C_i$ on a $a_{\sigma(i) j} = a_{\sigma(i) i}$. On a donc
        $$a_{(\sigma \circ \tau)(k) k} = a_{(\sigma \circ \tau)(j) j} = a_{\sigma(i) i}$$
    \end{itemize}
    On a donc
    \begin{eqnarray*}
      a_{(\sigma \circ \tau)(1) 1} \cdot \ldots \cdot a_{(\sigma \circ \tau)(i) i} \cdot \ldots \cdot a_{(\sigma \circ \tau)(j) j} \cdot \ldots \cdot a_{(\sigma \circ \tau)(n) n} \\
        = a_{\sigma(1) 1} \cdot \ldots \cdot a_{\sigma(j) j} \cdot \ldots \cdot a_{\sigma(i) i} \cdot \ldots \cdot a_{\sigma(n) n} \\
        = a_{\sigma(1) 1} \cdot \ldots \cdot a_{\sigma(i) i} \cdot \ldots \cdot a_{\sigma(j) j} \cdot \ldots \cdot a_{\sigma(n) n} \\
    \end{eqnarray*}
    %
    De plus $\epsilon(\sigma \circ \tau) = \epsilon(\sigma) \cdot \epsilon(\tau)$ où on a $\epsilon(\tau) = -1$, donc
    $$\epsilon(\sigma \circ \tau) = -\epsilon(\sigma)$$
    Par conéquent 
    $$p_{\sigma \circ \tau}(C_1, C_2, \ldots, C_n) = -p_{\sigma}(C_1, C_2, \ldots, C_n)$$
    Ainsi pour tout $i\in \{1; \ldots; \frac{n!}{2}\}$
    \begin{eqnarray*}
      p_{\sigma_i \circ \tau}(C_1, C_2, \ldots, C_n) &=& -p_{\sigma_i}(C_1, C_2, \ldots, C_n) \\
      p_{\sigma_i \circ \tau}(C_1, C_2, \ldots, C_n) &+& p_{\sigma_i}(C_1, C_2, \ldots, C_n) ~=~ 0
    \end{eqnarray*}
    Il s'ensuit que $det(C_1, \ldots, C_i, \ldots, C_j(=C_i), \ldots, C_n) = 0$
\end{enumerate}

\paragraph{Remarque} Soient $A, B \in M_{n \times n}(\R)$, $\lambda \in \R$. En général,
\begin{eqnarray*}
  det(A + B) &\neq& det(A) + det(B) \\
  det(\lambda A) &\neq& \lambda det(A)
\end{eqnarray*}
En fait, on a $det(\lambda A) = \lambda^{n} det(A)$.

\paragraph{Corollaire} Soient $i, j \in \{1; \ldots; n\}$, $i\neq j$ et $C_1, C_2, \ldots, C_n$ $n$ matrices colonnes £ $n$ lignes. Alors
$$det(C_1, \ldots, C_i, \ldots, C_j, \ldots, C_n) = -det(C_1, \ldots, C_j, \ldots, C_i, \ldots, C_n)$$

\paragraph{Démonstration} On a
\begin{eqnarray*}
  0 =& det(C_1, \ldots, C_i+C_j, \ldots, C_i+C_j, \ldots, C_n) \\
    =& det(C_1, \ldots, C_i, \ldots, C_i+C_j, \ldots, C_n) \\
    &+ det(C_1, \ldots, C_j, \ldots, C_i+C_j, \ldots, C_n) \\
    =& det(C_1, \ldots, C_i, \ldots, C_i, \ldots, C_n) \\
    &+ det(C_1, \ldots, C_i, \ldots, C_j, \ldots, C_n) \\
    &+ det(C_1, \ldots, C_j, \ldots, C_i, \ldots, C_n) \\
    &+ det(C_1, \ldots, C_j, \ldots, C_j, \ldots, C_n) \\
    =& 0 \\
    &+ det(C_1, \ldots, C_i, \ldots, C_j, \ldots, C_n) \\
    &+ det(C_1, \ldots, C_j, \ldots, C_i, \ldots, C_n) \\
    &+ 0 \\
    =& det(C_1, \ldots, C_i, \ldots, C_j, \ldots, C_n) + det(C_1, \ldots, C_j, \ldots, C_i, \ldots, C_n) = 0
\end{eqnarray*}
On dit alors que l'application 
$$det: M_{n \times 1}(\R) \times \ldots \times M_{n\times 1}(\R) \rightarrow \R$$
est antisymétrique.

\paragraph{Théorème} Soit $A =(a_{ij})$ une matrice carrée de taille $n\times n$. Alors
$$det(A^{T}) = det(A)$$

\paragraph{Démonstration} On observe que l'application
\begin{eqnarray*}
  S_n &\rightarrow& S_n \\
  \sigma &\mapsto& \sigma^{-1}
\end{eqnarray*}
est bijective (elle est sa propre bijection réciproque). Il vient
\begin{eqnarray*}
  det(A^{T}) &=& \sum_{\sigma \in S_n} p_{\sigma}(A^{T}) \\
    &=& \sum_{\sigma^{-1} \in S_n} p_{\sigma^{-1}}(A^{T})
\end{eqnarray*}
Soit $\sigma \in S_n$
$$p_{\sigma^{-1}}(A^{T}) = \epsilon(\sigma^{-1}) \cdot (A^{T})_{\sigma^{-1}(1) 1} \cdot \ldots \cdot (A^{T})_{\sigma^{-1}(n) n}$$
On a $\epsilon(\sigma) \epsilon(\sigma^{-1}) = \epsilon(\sigma \circ \sigma^{-1}) = \epsilon(id) = 1$. Puisque $\epsilon(\sigma) \pm 1$ et $\epsilon(\sigma^{-1}) \pm 1$, on a 
$$\epsilon(\sigma) = \epsilon(\sigma^{-1})$$
Maintenant
$$(A^{T})_{\sigma^{-1}(1) 1} \cdot \ldots \cdot (A^{T})_{\sigma^{-1}(n) n} = A_{1 \sigma^{-1}(1)} \cdot \ldots \cdot A_{n \sigma^{-1}(n)}$$
Comme $\sigma^{-1}: \{1; \ldots; n\} \rightarrow \{1; \ldots; n\}$ est bijective on a
\begin{eqnarray*}
  A_{1 \sigma^{-1}(1)} \cdot \ldots \cdot A_{n \sigma^{-1}(n)} &=& \prod_{j=1}^n A_{j \sigma^{-1}(j)} \\
    &=& \prod_{k=1}^n A_{\sigma(k) k} ~~ (\text{on a posé } k = \sigma^{-1}(j))
\end{eqnarray*}
Donc $p_{\sigma^{-1}}(A^{T}) = p_{\sigma}(A)$. Par suite
$$det(A^{T}) = \sum_{\sigma \in S_n} p_{\sigma}(A) = det(A)$$

\paragraph{Lemme} Soit $\sigma \in S_n$ telle que pour tout $i \in \{1; \ldots; n\}$, $\sigma(i) \leq i$. Alors $\sigma  = id$. En effet on a
\begin{itemize}
  \item $1 \leq \sigma(1) \leq 1$ (par hypothèse), donc $\sigma(1) = 1$.
  \item on a $\sigma(2) \neq \sigma(1) = 1$, donc $\sigma(2) \geq 2$, et par hypothèse $\sigma(2) \leq 2$. Par suite $\sigma(2) = 2$.
  \item Ainsi de suite.
\end{itemize}
Il est équivalent de dire que si une permutations $\sigma \in S_n$ est différendte de $id$, alors il existe $i \in \{1; \ldots; n\}$ tel que $\sigma(i) > i$.

\paragraph{Théorème} Le déterminant d'une matrice carré triangulaire supérieure (resp. triangulaire inférieure) est àgal au produit des ses coefficients diagonaux.

\paragraph{Démonstration}  Soit $A = (a_ij)$ une matrice carrée de taille $n \times n$ triangulaire supérieure. Il vient 
$$det(A) = p_{id}(A) + \sum_{\sigma \in S_n, \sigma \neq id} p_{\sigma}(A)$$
Si $\sigma \neq id$, alors, d'après le lemme, il existe $j \in \{1; \ldots; n \}$ tel que $\sigma(j) > j$. Puisque $A$ est triangulaire supérieure, $a_{\sigma(j) j} = 0$. Par suite $p_{\sigma}(A) = 0$ et donc 
$$\sum_{\sigma \in S_n, \sigma \neq id} p_{\sigma}(A) = 0$$
Il reste
$$det(A) = p_{id}(A) = a_{11} \cdot a_{22} \cdot \ldots \cdot a_{nn}$$
Le cas "triangulaire inférieure" se déduit du cas "triangulaire supérieure" par transposition.

%
\subsection{Le déterminant sous l'effet des opérations élémentaires}
%
Les résultats précédents indiquent comment se comporte le déterminant sous l'effet des opérations élémentaires sur les lignes d'une matrice:
\begin{itemize}
  \item Le déterminant ne change pa si on ajout à une ligne un multiple d'une autre ligne
    $$\begin{vmatrix} L_1 \\ L_2 + 4 L_3 \\ L_3 \end{vmatrix} 
      = \begin{vmatrix} L_1 \\ L_2 \\ L_3 \end{vmatrix} + 4 \cdot \begin{vmatrix} L_1 \\ L_3 \\ L_3 \end{vmatrix}
      = \begin{vmatrix} L_1 \\ L_2 \\ L_3 \end{vmatrix} + 0
      = \begin{vmatrix} L_1 \\ L_2 \\ L_3 \end{vmatrix}$$
      
  \item Lorsque on multiplie une ligne par un réel, le déterminant est multiplié par ce réel
    $$\begin{vmatrix} 5 L_1 \\ L_2 \\ L_3 \end{vmatrix} = 5 \cdot \begin{vmatrix} L_1 \\ L_2 \\ L_3 \end{vmatrix}$$
    
  \item Lorsque on permute deux lignes, le déterminant est multiplié par $-1$
    $$\begin{vmatrix} L_1 \\ L_3 \\ L_2 \end{vmatrix} = -1 \cdot \begin{vmatrix} L_1 \\ L_2 \\ L_3 \end{vmatrix}$$
\end{itemize}

\paragraph{Remarque} Le deux premières propriétés découlent de la multilinéarité du détérminant.

%
\subsection{Calculer un déterminant avec l'algorithme de Gauss}
%
\paragraph{Méthode de calcul} On peut donc calculer un déterminant un utilisant l'algorithme d'élimination de Gauss. Par des opérations élémentaires sur les lignes ou sur les colonnes, on met la matrice sous la forme triangulaire. On applique à chaque étape les régles du calcul du déterminant. Le déterminant est alors égal au produit des coefficients diagonaux de cette matrice triangulaire.

%
%
\section{Inversibilité des matrices et déterminant}
%
%
\paragraph{Théorème} Soient $A$ et $B$ deux matrices carrées de même taille. Alors 
$$det(A B) = det(A) \cdot det(B)$$

\paragraph{Démonstration} Nous nous contentans ici de montros cette formule dasn le cas de matrices de taille $3 \times 3$, le cas général se traite de façon analogue. \\
Soient $A$ et $B$ deux matrices de taille $3 \times 3$. On note $C_1, C_2, C_3$ les colonnes de $A$
$$A = (C_1, C_2, C_3) \text{ et } B=(b_{ij})_{1 \leq i, j \leq n}$$
On observe que
$$A B = \left(
  A \begin{pmatrix} b_{11} \\ b_{21} \\ b_{31} \end{pmatrix} ~ 
  A \begin{pmatrix} b_{12} \\ b_{22} \\ b_{32} \end{pmatrix} ~ 
  A \begin{pmatrix} b_{13} \\ b_{23} \\ b_{33} \end{pmatrix}
\right)$$
Pour $i \in \{1; 2; 3\}$, on a également
\begin{eqnarray*}
  A \begin{pmatrix} b_{1i} \\ b_{2i} \\ b_{3i} \end{pmatrix}
  &=& A \left( b_{1i} \begin{pmatrix} 1 \\ 0 \\ 0 \end{pmatrix} + b_{2i} \begin{pmatrix} 0 \\ 1 \\ 0 \end{pmatrix} + b_{3i} \begin{pmatrix} 0 \\ 0 \\ 1 \end{pmatrix} \right) \\
    &=& b_{1i} A \begin{pmatrix} 1 \\ 0 \\ 0 \end{pmatrix} + b_{2i} A \begin{pmatrix} 0 \\ 1 \\ 0 \end{pmatrix} + b_{3i} A \begin{pmatrix} 0 \\ 0 \\ 1 \end{pmatrix} \\
    &=& b_{1i} C_1 + b_{2i} C_2 + b_{3i} C_3
\end{eqnarray*}
Il vient
$$det(A B) = \begin{vmatrix} \\ b_{11} C_1 + b_{21} C_2 + b_{31} C_3 + b_{12} C_1 + b_{22} C_2 + b_{32} C_3 + b_{13} C_1 + b_{23} C_2 + b_{33} C_3 \\ \\ \end{vmatrix}$$
On développe ce déterminant par multilinéairté. On obtient $3^3 = 27$ termes. Deux sortes de termes:
\begin{itemize}
  \item Ceux qui correspondent au choix d'une permutations $\sigma \in S_3$ des colonnes $C_1, C_2, C_3$:
    $$b_{\sigma(1) 1} \cdot b_{\sigma(2) 2} \cdot b_{\sigma(3) 3} \cdot \begin{vmatrix} C_{\sigma(1)} & C_{\sigma(2)} & C_{\sigma(3)} \end{vmatrix}$$
    
  \item Les autres pour lesquels au moins deux retenues sur les trois sont égales. Alors le déterminant correspondant est nul, et donc le terme lui-même est nul.
\end{itemize}
On obtient donc
$$det(A B) = \sum_{\sigma \in S_3} b_{\sigma(1) 1} \cdot b_{\sigma(2) 2} \cdot b_{\sigma(3) 3} \cdot \begin{vmatrix} C_{\sigma(1)} & C_{\sigma(2)} & C_{\sigma(3)} \end{vmatrix}$$
où pour tout $\sigma \in S_3$,
\begin{eqnarray*}
  \begin{vmatrix} C_{\sigma(1)} & C_{\sigma(2)} & C_{\sigma(3)} \end{vmatrix}
  &=& \epsilon(\sigma) \begin{vmatrix} C_1 & C_2 & C_ 3 \end{vmatrix} \\
    &=& \epsilon(\sigma) \cdot det(A)
\end{eqnarray*}
D'où
\begin{eqnarray*}
  det(A B) &=& \sum_{\sigma \in S_3} \epsilon(\sigma) \cdot b_{\sigma(1) 1} \cdot b_{\sigma(2) 2} \cdot b_{\sigma(3) 3} \cdot det(A) \\
    &=& det(A) \left( \sum_{\sigma \in S_3} \epsilon(\sigma) \cdot b_{\sigma(1) 1} \cdot b_{\sigma(2) 2} \cdot b_{\sigma(3) 3} \right) \\
    &=& det(A) \cdot det(B)
\end{eqnarray*}

\paragraph{Théorème} Soit $A$ une matrice carrée de taille $n \times n$, alors 
$$A \text{ est inversible } \Leftrightarrow det(A) \neq 0$$

\paragraph{Démonstration} 
\begin{itemize}
  \item [$\Rightarrow$] Supposons que $A$ est inversible. On a donc
    $$A A^{-1} = I_n$$
    Il vient
    $$det(A) \cdot det(A^{-1}) = det(AA^{-1}) = det(I_n) = 1 \neq 0$$
    Cela implqiue que $det(A) \neq 0$
  
  \item [$\Leftarrow$] Réciproquement, montrons que si $A$ n'est pas inversible, alors $det(A) = 0$. Supposons docn que $A$ ne soit pas inversible. Considérons le système 
    $$A \cdot X = 0$$
    Puisque $A$ n'est pas inversible et que $0$ est solution de cesystème, ce système admet une infinité de solutions. Il existe donc des réels $\alpha_1, \ldots, \alpha_n$ non tous nuls tels que
    $$A \begin{pmatrix} \alpha_1 \\ \vdots \\ \alpha_n \end{pmatrix} = 0$$
    Soient $C_1, \ldots, C_n$ les colonnes de $A$. On a 
    $$0 = A \begin{pmatrix} \alpha_1 \\ \vdots \\ \alpha_n \end{pmatrix} = \alpha_1 \cdot C_1 + \ldots + \alpha_n \cdot C_n$$
    Soit $i_0 \in \{1; \ldots; n \}$ tel que $\alpha_{i_0} \neq 0$. On obtient 
    $$C_{i_0} = - \sum_{i=1, i\neq i_0}^n \frac{\alpha_i}{\alpha_{i_0}} C_i$$
    Cela entraîne que
    \begin{eqnarray*}
      det(A) &=& \begin{vmatrix} \\
        C_1 & \ldots & C_{i_0} & \ldots & C_i & \ldots & C_n 
      \\ \\ \end{vmatrix} \\
        &=& \begin{vmatrix} \\
          C_1 & \ldots & - \sum_{i=1, i\neq i_0}^n \frac{\alpha_i}{\alpha_{i_0}} C_i & \ldots & C_i & \ldots & C_n 
        \\ \\\end{vmatrix} \\
        &=& - \sum_{i=1, i\neq i_0}^n \frac{\alpha_i}{\alpha_{i_0}} \begin{vmatrix} \\
          C_1 & \ldots & C_{i} & \ldots & C_i & \ldots & C_n 
        \\ \\ \end{vmatrix}
    \end{eqnarray*}
    Dans le $i^{\text{ème}}$ terme de cette somme la colonne $C_i$ apparaît en position $i$ et $i_0$ donc
    $$\begin{vmatrix} \\ C_1 & \ldots & C_{i_0} & \ldots & C_i & \ldots & C_n \\ \\ \end{vmatrix} = 0$$
    Par suite
    $$det(A) = 0$$
\end{itemize}

%
\subsection{Cofacteur d'une matrice}
%
\paragraph{Définition} Soit $A = (a_{ij})$ une matrice carrée de taille $n\times n$. Soit $(i ~ j) \in \{1; \ldots; n\} \times \{1; \ldots; n \}$. On appelle cofacteur de $A$ associé à $(i ~ j)$ le nombre réel défini par
$$\Delta_{ij} = (-1)^{i+j} \begin{vmatrix}
  a_{11} & \ldots & a_{1 j-1} & a_{1 j+1} & \ldots & a_{1n} \\
  \vdots &  & \vdots & \vdots &  & \vdots \\
  a_{i-1 1} & \ldots & a_{i-1 j-1} & a_{i-1 j+1} & \ldots & a_{i-1 n} \\
  a_{i+1 1} & \ldots & a_{i+1 j-1} & a_{i+1 j+1} & \ldots & a_{i+1 n} \\
  \vdots &  & \vdots & \vdots &  & \vdots \\
  a_{n 1} & \ldots & a_{n j-1} & a_{n j+1} & \ldots & a_{nn}
\end{vmatrix}$$
Ce déterminant (de matrice de taille $(n-1) \times (n-1)$) est obtenu à partir de celui de $A$ en supprimant le $i^{\text{ème}}$ ligne et la $j^{\text{ème}}$ colonne.

\paragraph{Exemple} Soit
$$A = \begin{pmatrix}
  1 & -5 & -1 & 0 \\
  2 & 1 & 2 & 3 \\
  3 & 7 & 3 & 1 \\
  0 & 1 & 0 & 8
\end{pmatrix}$$
Alors on a
\begin{eqnarray*}
  \Delta_{23} &=& (-1)^{2+3} \begin{vmatrix} 1 & -5 & 0 \\ 3 & 7 & 1 \\ 0 & 1 & 8 \end{vmatrix}
    = - \begin{vmatrix} 1 & -5 & 0 \\ 3 & 7 & 1 \\ 0 & 1 & 8 \end{vmatrix} \\
  \Delta_{42} &=& (-1)^{4 + 2} \begin{vmatrix} 1 & -1 & 0 \\ 2 & 2 & 3 \\ 3 & 3 & 1 \end{vmatrix}
    = - \begin{vmatrix} 1 & -1 & 0 \\ 2 & 2 & 3 \\ 3 & 3 & 1 \end{vmatrix}
\end{eqnarray*}

%
\subsection{Calculer un déterminant par développement}
%
\paragraph{Théorème} Soit $A$ une matrice carrée de taille $n\times n$. Soit $j \in \{1; \ldots; n\}$. Alors
$$det(A) = \sum_{i=1}^{n} a_{ij} \Delta_{ij}$$
On dit que l'on développe $det(A)$ par rapport à la $j^{\text{ème}}$ colonne.

\paragraph{Exemple} Développons $\begin{vmatrix} 1 & -2 & 0 \\ 7 & 1 & 2 \\ 3 & 5 & 3 \end{vmatrix}$ par rapport à la $3^{\text{ème}}$ ligne
$$\begin{vmatrix} 1 & -2 & 0 \\ 7 & 1 & 2 \\ 3 & 5 & 3 \end{vmatrix} = 
  0 \cdot \begin{vmatrix} 7 & 1 \\ 3 & 5 \end{vmatrix} 
  - 2 \cdot \begin{vmatrix} 1 & -2 \\ 3 & 5 \end{vmatrix} 
  + 3 \cdot \begin{vmatrix} 1 & -2 \\ 7 & 1 \end{vmatrix} 
= 23$$

\paragraph{Théorème} Soit $A$ une matrice carrée de taille $n\times n$. Soit $i \in \{1; \ldots; n\}$. Alors
$$det(A) = \sum_{j=1}^{n} a_{ij} \Delta_{ij}$$
On dit que l'on développe $det(A)$ par rapport à la $i^{\text{ème}}$ ligne.

\paragraph{Démonstration} On démontre la formule de développememt du déterminant suivant une colonne, la formule de développement suivant une ligne s'en déduisant par transposition. \\
Soit $A = (a_{j})$ une matrice de taille $n \times n$.
$$det(A) = \sum_{\tau \in S_n} p_{\tau}(A)$$
Soit $j \in \{1; \ldots; n \}$, pour tout couple $(k, l) \in  \{1; \ldots; n \}\times\{1; \ldots; n \}$ on note
$$T_{kl} = \{\tau \in S_n \vert k = \tau(l) \}$$
On a $S_n = T_{1j} \cup T_{2j} \cup \ldots \cup T_{nj}$ (union disjointe). Il vient
$$det(A) = \sum_{\tau \in T_{1j}} p_{\tau}(A) + \sum_{\tau \in T_{2j}} p_{\tau}(A) + \ldots + \sum_{\tau \in T_{nj}} p_{\tau}(A)$$
Soit $i \in \{1; \ldots; n\}$. Montrons que $\sum_{\tau \in T_{ij}} p_{\tau}(A) = a_{ij} \Delta_{ij}$. On considère la matrice $B$ construite à partir de $A$ en permutant la $j^{\text{ème}}$ colonne de $A$ avec les colonnes uivantes de façon à l'amener à la place de la $n^{\text{ème}}$ colonne et en fasant une démarche analoque avec la $i^{\text{ème}}$ ligne. On fait donc subir aux colonnes de $A$ la permutation
$$d^{-1} = (n-1 ~~ n) \circ \ldots \circ (j+ 1 ~~ j + 2) \circ (j ~~ j+1) = \begin{pmatrix}j & n & n-1 & \ldots & j + 2 & j + 1\end{pmatrix}$$
et aux lignes de $A$ la permutation
$$c^{-1} = (n-1 ~~ n) \circ \ldots \circ (i+ 1 ~~ i + 2) \circ (i ~~ i+1) = \begin{pmatrix}i & n & n-1 & \ldots & i + 2 & i + 1\end{pmatrix}$$
On a pour tout $(k, l) \in \{1; \ldots; n \}\times\{1; \ldots; n \}$
$$b_{kl} = a_{c(k)d(l)}$$
On observe que l'application
\begin{eqnarray*}
  \phi: T_{n n} &\rightarrow& T_{ij} \\
  \tau &\mapsto& c \circ \tau \circ d^{-1}
\end{eqnarray*}
est bijective. \footnote{Sa bijections réciproque est
\begin{eqnarray*}
  \psi: T_{ij} &\rightarrow& T_{n n} \\
  \tau &\mapsto& c^{-1} \circ \tau \circ d
\end{eqnarray*}
On a
$$\phi \circ \psi = id_{T_{ij}} \text{ et } \psi \circ \phi = id_{T_{n n}}$$}
Il vient
\begin{eqnarray*}
  \sum_{\tau \in T_{ij}} p_{\tau}(A) &=& \sum_{\tau \in T_{ij}} \epsilon(\tau) \prod_{l=1}^{n} a_{\tau(l) l} \\
    &=& \sum_{\tau \in T_{ij}} \epsilon(\phi(\tau)) \prod_{l=1}^{n} a_{\phi(\tau(l)) l} \\
    &=& \sum_{\tau \in T_{n n}} \epsilon(c \circ \tau \circ d^{-1}) \prod_{l=1}^{n} a_{(c \circ \tau \circ d^{-1})(l) l} \\
    &=& \sum_{\tau \in T_{n n}} \epsilon(c) \epsilon(d^{-1}) \epsilon(\tau) \prod_{l=1}^{n} a_{c(\tau(l')) ~ d(l')} ~ (\text{on pose } l' = d^{-1}(l))\\
\end{eqnarray*}
On a $\epsilon(c) = \epsilon(c^{-1}) = (-1)^{n-i}$ car $c^{-1}$ est le produit de $n-i$ transpositions et $\epsilon(d^{-1}) = (-1)^{n-j}$ car $d^{-1}$ est le produit de $n-j$ transpositions, d'où $\epsilon(c) \epsilon(d^{-1}) = (-1)^{2n - (i+j)}$. Comme $(2n - (i+j)) + (i+j) = 2n$, on a $2n - (i+j)$ et $i+j$ ont mêm parité donc $(-1)^{2n - (i+j)} = (-1)^{i+j}$. Par suite
$$\epsilon(c) \epsilon(d^{-1}) = (-1)^{i+j}$$
Pour tout $l' \in \{1; \ldots; n \}$, $a_{c(\tau(l')) ~ d(l')} = b_{\tau(l') ~ l'}$. On obtient donc
\begin{eqnarray*}
  \sum_{\tau \in T_{ij}} p_{\tau}(A) &=& (-1)^{i+j} \sum_{\tau \in T_{nn}} \epsilon(\tau) \prod_{l'=1}^{n} b_{\tau(l') ~ l'} \\
    &=& (-1)^{i+j} b_{nn} \sum_{\tau \in T_{nn}} \epsilon(\tau) \prod_{l' = 1}^{n-1} b_{\tau(l') ~ l'} \\
    &=& a_{ij} \Delta_{ij}
\end{eqnarray*}

%
\subsection{Comatrice}
%
\paragraph{Définition} Soit $A$ une matrice carrée de taille $n \times n$. On appelle comatrice de $A$ et on note $com(A)$ la matrice carrée de taille $n \times n$ dont les coefficients sont les cofacteurs de $A$, c'est-à-dire pour tous $1 \leq i, j \leq n$
$$(com(A))_{ij} = \Delta_{ij}$$

\paragraph{Exemple} Soit $A = \begin{pmatrix} 1 & -4 & 2 \\ 0 & 3 & -1 \\ 2 & 5 & 0 \end{pmatrix}$. On a
$$com(a) = \begin{pmatrix}
  \begin{vmatrix} 3 & -1 \\ 5 & 0 \end{vmatrix} & -\begin{vmatrix} 0 & -1 \\ 2 & 0 \end{vmatrix} & \begin{vmatrix} 0 & 3 \\ 2 & 5 \end{vmatrix} \\
  -\begin{vmatrix} -4 & 2 \\ 5 & 0 \end{vmatrix} & \begin{vmatrix} 1 & 2 \\ 2 & 0 \end{vmatrix} & -\begin{vmatrix} 1 & -4 \\ 2 & 5 \end{vmatrix} \\
  \begin{vmatrix} -4 & 2 \\ 3 & -1 \end{vmatrix} & -\begin{vmatrix} 1 & 2 \\ 0 & -1 \end{vmatrix} & \begin{vmatrix} 1 & -4 \\ 0 & 3 \end{vmatrix}
\end{pmatrix} = \begin{pmatrix}
  5 & -2 & -6 \\
  10 & -4 & -13 \\
  -2 & 1 & 3
\end{pmatrix}$$

\paragraph{Théorème} Soit $A$ une matrice carrée de taille $n \times n$. On a
$$A \cdot com(A)^{T} = com(A)^{T} \cdot A = det(A) \cdot I_n$$

\paragraph{Théorème} Si $A$ est inversible, alors $det(A) \neq 0$ et 
$$A^{-1} = \frac{1}{det(a)} com(A)^{T}$$

\paragraph{Remarque} Cette formule généralise celle qui a été vue dans le cas des matrices de taille $2 \times 2$.

%
%
\section{Systèmes de cramer}
%
%
\paragraph{Définition} On dit qu'un système linéaire $A \cdot X = B$ à $n$ équations et $n$ inconnues, $A$ matrice carrée de taille $n \times n$, $B$ matrice colonée de taille $n\times 1$ est un système de cramer si la matrice $A$ du système est inversible. \\
Dans ce cas le système admet une solution unique $(a_1, \ldots, a_n) \in \R^n$ et les $a_i \in \R$ sont donnés par les formules suivantes. Si on désigne par $C_1, \ldots, C_n$ les colonnes de $A$\footnote{$A = (C_1, \ldots, C_n)$}, on a
$$a_i = \frac{\begin{vmatrix} C_1 & \ldots & B_{(i)} & \ldots & C_n \end{vmatrix}}{det(A)} ~ (\text{on remplace } C_i \text{ avec } B)$$
Comme $A$ est inversible, $det(A) \neq 0$.

\paragraph{Démonstration} On a $B = A \begin{pmatrix} a_1 \\ \vdots \\ a_n \end{pmatrix} = a_1 C_1 + \ldots + a_n C_n$. Il vient
\begin{eqnarray*}
  \begin{vmatrix} C_1 & \ldots & B_{(i)} & \ldots & C_n \end{vmatrix} &=& \begin{vmatrix} C_1 & \ldots &  a_1 C_1 + \ldots + a_n C_n & \ldots & C_n \end{vmatrix} \\
    &=& a_1 \begin{vmatrix} C_1 & \ldots & C_1 & \ldots & C_n \end{vmatrix} \\
    &&+ \ldots \\
    &&+ a_i \begin{vmatrix} C_1 & \ldots & C_i & \ldots & C_n \end{vmatrix} \\
    &&+ \ldots \\
    &&+ a_n \begin{vmatrix} C_1 & \ldots & C_n & \ldots & C_n \end{vmatrix}
\end{eqnarray*}
On a 
$$a_i \begin{vmatrix} C_1 & \ldots & C_i & \ldots & C_n \end{vmatrix} = a_i det(A)$$
Pour $j \in \{1; \ldots; n\}$, $j\neq i$
$$a_i \begin{vmatrix} C_1 & \ldots & C_j & \ldots & C_n \end{vmatrix} = 0$$
car la matrice colonne $C_j$ apparaît deux fois , en positions $i$ et $j$. On obtient donc 
$$\begin{vmatrix} C_1 & \ldots & B_{(i)} & \ldots & C_n \end{vmatrix} = a_i det(A)$$
d'où
$$a_i = \frac{\begin{vmatrix} C_1 & \ldots & B_{(i)} & \ldots & C_n \end{vmatrix}}{det(A)}$$

%
%
\section{Récapitulatif}
%
%

%
\subsection{Méthodes de calcul du déterminant}
%
Pour calculer le déterminant d'une matrice, on peut:
\begin{itemize}
  \item utilise la définition du déterminant comme somme des produits élémentaires singés convient pour les matrices de taille $1 \times 1$ ou $2 \times 2$
    $$\begin{array}{lcr} det\big((a)\big) = a & & det\left(\begin{pmatrix} a & b \\ c & d \end{pmatrix}\right) = ad - bc \end{array}$$
  \item développer suivant une ligne ou une colonne convient pour les matrice de taille $3 \times 3$, éventuellement aussi pour une taille de $4 \times 4$
  \item utiliser l'algorithme d'élimination de Gauss convient pour les matrices de taille $2 \times 2$ et plus.
\end{itemize}

%
\subsection{Méthodes de calcul de l'inverse d'une matrice}
Pour calculer  l'inverse d'une matrice\footnote{si l'inverse existe}, on peut
\begin{itemize}
  \item calculer la comatrice de cette matruce convient pour des matrices de taille $2 \times 2$ et $3 \times 3$.
  \item utiliser l'algorithme d'élimination de Gauss convient pour des matrice de taille $3 \times 3$ et plus.
\end{itemize}
