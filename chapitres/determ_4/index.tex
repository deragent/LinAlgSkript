\chapter{Le déterminant}

%
%
\section{Groupes symétriques}
%
%
%
\subsection{Permutation}
%
\paragraph{Définition} Soit $E$ un ensemble. On appelle permutation de $E$ un bijection  de $E$ dans $D$. On note $Sym(e)$ l'ensemble de permutations de $E$

\paragraph{Définition} On munit $Sym(E)$ de la composition
\begin{eqnarray*}
  \circ: Sym(E) \times Sym(E) &\rightarrow& Sym(E) \\
  (\sigma , \tau) &\mapsto& \sigma \circ \tau
\end{eqnarray*}
Par définition, pour tout $x\in E$
$$(\sigma \circ \tau)(x) = \sigma(\tau(x))$$
La composée de deux biijections étant encore une bijection, la composée de deux permutations de $E$ est encore une permutation de $E$.

%
\subsection{Groupe symétrique}
%
Alors $(Sym(E), \circ)$ est un groupe. En effet
\begin{itemize}
  \item la composition des permutations est associative
    $$\alpha \circ (\beta \circ \gamma) = (\alpha \circ \beta) \circ \gamma ~ \forall \alpha, \beta, \gamma \in Sym(E)$$
  
  \item l'application
    \begin{eqnarray*}
      id_E: E &\rightarrow& E \\
      x &\mapsto& id_E(x) = x 
    \end{eqnarray*}
    est une permutation de $E$ qui est élément neuter pour $circ$
    
  \item si $\sigma \in Sym(E)$, alors la permutation inverse de $\sigma$ est la bijection réciproque $\sigma^{-1}: E \rightarrow E$ de $\sigma$
\end{itemize}
On appelle ce groupe le groupe symétrique de $E$.

\paragraph{Remarque} Dans la suite nous nous concentrons sur le cas où $E = \{1; 2; \ldots; n\}$ pour un certain entier naturel $n\geq 1$. On note alors
$$S_n = Sym(\{1; 2; \ldots; n\})$$
Si $\sigma \in S_n$, on pourra écrire
$$\sigma = \begin{pmatrix} 1 & 2 & \ldots & n \\ \sigma(1) & \sigma(2) & \ldots & \sigma(n) \end{pmatrix}$$

%
\subsection{Support}
%
\paragraph{Définition} Pour tout $\sigma \in S_n$, on appelle support de $\sigma$ et on note $supp(\sigma)$ l'ensemble
$$supp(\sigma) = \{i \in \{1; 2; \ldots; n\} \vert \sigma(i) \neq i\}$$

%
\subsection{Cycle}
%
\paragraph{Définition} Soit $n \geq 1$ un entier naturel et soit $k \in \{1; 2; \ldots; n\}$. On dit qu'une permutation $\sigma \in S_n$ est un cycle de longeur $k$ ou $k$-cycle, s'il existe $i_1, i_2, \ldots, i_k \in  \{1; 2; \ldots; n\}$ tels que
$$\sigma(i_1) = i_2 \rightarrow \sigma(i_2) = i_3 \rightarrow \ldots \rightarrow \sigma(i_{k-1}) = i_k \rightarrow \sigma(i_k) = i_1$$
et $\sigma(i) = i$ si $i \notin \{i_1; i_2; \ldots; i_k\}$

\paragraph{Remarque} L'ensemble $\{i_1; i_2; \ldots; i_k\}$ est le support du $k$-cycle.

\paragraph{Notation} Soit $\sigma$ un $k$-cycle, on note $\sigma = (i_1 ~ i_2 ~ \ldots ~ i_k)$


%
\subsection{Transposition}
%
\paragraph{Définition} Les 2-cycles de $S_n$ s'appellent les transpositions de $S_n$

\paragraph{Proposition} Soit $m \geq 2$ un entier naturel. Alors toute permutation de $S_n$ peut sécrire comme composée de transpositions.

\paragraph{Démonstration}  On raisonne par récurence sur le cardinal\footnote{Le cardinal d'un ensemble fini est le nombre de ses éléments.} de $supp(\sigma)$.
\subparagraph{Annonce de la récurence} Soit $\sigma \in S_n$ telle que $supp(\sigma)$ soit de cardinal égal à $0$. Donc $supp(\sigma)$ est vide (on note $supp(\sigma) = \emptyset$). Autrement dit, $\sigma$ fixe tous les éléments de $\{1; 2; \ldots; n\}$. Par conséquent, $\sigma = id$. \\
On peut écrire $\sigma = id = (1 ~ 2)\circ(1 ~ 2)$, ce qui est une écriture de $\sigma$ comme composée de transpositions.

\subparagraph{Hypothése de récurence} Soit $k \in \{1; 2; \ldots; n\}$. On suppose que pour tout $\tau \in S_n$, telle que $card(supp(\tau)) \leq k-1$, $\tau$ s'écrit comme composée de transposition.

\subparagraph{Pas de récurence} Soit $\sigma \in S_n$ telle que le cardinal de $supp(\sigma)$ soit égal à $k$.
$$supp(\sigma) = \{i_1; i_2; \ldots; i_k\} \text{ avec } 1 \leq i_1 \leq i_2 \leq \ldots \leq i_k \leq n$$
On forme la permutation $\tau = (i_k ~ \sigma(i_k)) \circ \sigma$. La permutation $\tau$ a un support de cardinal $< k$. En effet, on verifie que $supp(\tau)$ est contenue dans $supp(\sigma)$. Or on a
\paragraph{[TO CHECK]}
$$\tau(i_k) = (i_k ~ \sigma(i_k)) \circ \sigma) (i_k) = (i_k ~ \sigma(i_k))(\sigma(i_k)) = i_k$$
Donc $supp(\tau)$ est contenue dans $\{i_1; i_2; \ldots; i_k-1\}$, donc est de cardinal $\leq k-1 < k$. Par hypothèse de récurence, $\tau$ s'écrit comme composée de transpositions
$$\tau = \tau_1 \circ \tau_2 \circ \ldots \circ \tau_n$$
On en déduit que 
\begin{eqnarray*}
  \sigma &=& (i_k ~ \sigma(i_k))^{-1} \circ \tau \\
    &=& (i_k ~ \sigma(i_k)) \circ \tau_1 \circ \tau_2 \circ \ldots \circ \tau_n
\end{eqnarray*}
\\
Par principe de récurence, la propriété est vraie pour toute permutation de $S_n$.

\paragraph{Proposition} Soit $n \geq 1$ un entier naturel. Alors $S_n$ est de cardinal $n! = 1 \cdot 2 \codt \ldots \cdot n$.

\paragraph{Démonstration} Pour construire une permutation $\sigma$ de $S_n$,
\begin{itemize}
  \item on choisit l'image $\sigma(1)$ de $1$ pour $\sigma$, il y a $n$ choix possibles.
  \item puis on choisit $\sigma(2)$ qui est l'image de $2$ par $\sigma$, il y a $n-1$ choix possile dans $\{1; 2; \ldots; n\} \backslash \{\sigma(1)\}$.
  \item puis on choisit $\sigma(3)$; il y a $n-1$ choix possibles dans $\{1; 2; \ldots; n\} \backslash \{\sigma(1); \sigma(2)\}$.
  \item ainsi de suite
\end{itemize}
Par conséquent, le nombre de permutations que l'on peut construire est 
$$n \cdot (n-1) \cdot \ldots \cdot 2 \cdot 1 = n!$$

\paragraph{Example} Décrivons $S_2$ et $S_3$
\begin{itemize}
  \item $S_2$ est de cardinal $2! = 2$. On a 
    $$S_2 = \{id; (1 ~ 2)\}$$
  \item $S_3$ est de cardinal $3! = 6$. On a
    $$S_3 = \{id; (1 ~ 2); (1 ~ 3); (2 ~ 3); (1 ~ 2 ~ 3); (1 ~ 3 ~ 2)\}$$
\end{itemize}

%
\subsection{Inversion de paire}
%
\paragraph{Définition} Soient $i, j \in \{1; 2; \ldots; n\}$, $i < j$, et $\sigma \in S_n$. On dit que $\sigma$ présente une inversion en la paire $(i, j)$ si 
$$\sigma(i) > \sigma(j)$$

%
\subsection{Permutation paire}
%
\paragraph{Définition} Soit $\sigma \in S_n$. On dit que $\sigma$ est une permutation paire si elle présente un nombre paire d'inversions, et une permutation impaire sinon.

%
\subsection{Signature}
%
\paragraph{Définition} On appelle signature de $\sigma$, et on note $\epsilon(\sigma)$ le nombre
$$\epsilon(\sigma) \left\{ \begin{array}{lr} 1 & \text{si } \sigma \text{ est une permutation paire} \\ -1 & \text{si } \sigma \text{ est une permutation impaire} \end{array}$$
Autrement dit, si $n_{\sigma}$ est le nombre d'inversions de $\sigma$ on a
$$\epsilon(\sigma) = (-1)^{n_{\sigma}} \in \{-1; 1\}$$

\paragraph{Example}
$$\sigma = \begin{pmatrix} 1 & 2 & 3 & 4 & 5 \\ 3 & 1 & 5 & 2 & 4 \end{pmatrix} \in S_5$$
Paires d'inversions
$$(1, 2), (1, 4), (3, 4), (3, 5)$$
$\sigma$ presente $4$ inversion, $\sigma$ est donc paire et $\epsilon(\sigma) = 1$

\paragraph{Théorème} Soient $\sigma, \tau \in S_n$. Alors
$$\epsilon(\sigma \circ \tau) = \epsilon(\sigma) \cdot \epsilon(\tau)$$

%
\subsection{Produit élémentaire}
%
\paragraph{Définition} Soit $A = (a_{ij})$ une matrice carrée de taille $n\times n$. Soit $\sigma in S_n$. On appelle produit élémentaire associé à $\sigma$ le nombre
$$a_{\sigma(1) 1} \cdot a_{\sigma(2) 2} \cdot \ldots \cdot a_{\sigma(n) n} = \prod_{i=1}^{n} a_{\sigma(i) i}$$
%
\subsection{Produit signé}
%
\paragraph{Définition} On appelle produit signé associé à $\sigma$ le nombre 
$$p_{\sigma}(A) = \epsilon(\sigma) \cdot a_{\sigma(1) 1} \cdot a_{\sigma(2) 2} \cdot \ldots \cdot a_{\sigma(n) n} = \epsilon(\sigma) \prod_{i=1}^{n} a_{\sigma(i) i}$$

%
\subsection{Déterminant}
%
\paragraph{Définition} Soit $A = (a_{ij})_{1 \leq i, j \leq n}$ une matrice carrée de taille $n \times n$. On appelle déterminant de $A$ le nombre
$$det(A) = \sum_{\sigma \in S_n} p_{\sigma}(A) = \sum_{\sigma \in S_n} \epsilon(\sigma) \prod_{i=1}^{n} a_{\sigma(i) i}$$

\paragraph{Example} Soit $A = \begin{pmatrix} 1 & 2 & 3 \\ 0 & 5 & 1 \\ -7 & 4 & -2 \end{pmatrix} \in M_{3}(\R)$.
$$S_3 = \{id; (1 ~ 2); (1 ~ 3); (2 ~ 3); (1 ~ 2 ~ 3); (1 ~ 3 ~ 2)\}$$
On a 
\begin{eqnarray*}
  \sigma = id           &\Rightarrow& p_{\sigma}(A) = 1 \cdot A_{11} \cdot A_{22} \cdot A_{33} \\
  \sigma = (1 ~ 2)      &\Rightarrow& p_{\sigma}(A) = 1 \cdot A_{21} \cdot A_{21} \cdot A_{33} \\
  \sigma = (1 ~ 3)      &\Rightarrow& p_{\sigma}(A) = 1 \cdot A_{31} \cdot A_{22} \cdot A_{13} \\
  \sigma = (2 ~ 3)      &\Rightarrow& p_{\sigma}(A) = 1 \cdot A_{11} \cdot A_{32} \cdot A_{23} \\
  \sigma = (1 ~ 2 ~ 3)  &\Rightarrow& p_{\sigma}(A) = 1 \cdot A_{21} \cdot A_{32} \cdot A_{13} \\
  \sigma = (1 ~ 3 ~ 2)  &\Rightarrow& p_{\sigma}(A) = 1 \cdot A_{31} \cdot A_{12} \cdot A_{23}
\end{eqnarray*}

\paragraph{Notation} Si $A = (a_{ij})_{1 \leq i, j\leq n}$ est une matrice carrée de taille $n\times n$ on note
$$\vert a_{ij} \vert _{1 \leq i, j \leq n} = det(A)$$

%
\subsection{Déterminant d'un système des matrices colonnes}
%
\paragraph{Définition} On peut aussi parler du döterminant d'un système de $n$ matrices colonnes $m$-lignes
$$C_1, C_2, \ldots, C_n  \in M_{n\times 1}(\R)$$
Suivant
$$C_{j} = \begin{pmatrix} c_{1j} \\ c_{2j} \\ \vdots \\ c_{nj} \end{pmatrix} \text{ pour tout } j \in \{1; \ldots ; n\}$$
on définit le déterminant du système $(C_1, C_2, \ldots, C_n)$ par
$$det(C_1, C_2, \ldots, C_n) = \sum_{\sigma \in S_n} \epsilon(\sigma) \cdot c_{\sigma(1) 1} \cdot \ldots \cdot c_{\sigma(n) n} \in \R$$
Si $C$ est la matrice de taille $n \times n$ dont les colonnes sont les $C_j$, $C = (C_1, C_2, \ldots, C_n)$ alors on a
$$det(C_1, C_2, \ldots, C_n) = det(C)$$
\paragraph{Remarque} Le point de vue adopté, matrice ou système de matrices colonnes sera clair d'après la notation et le contexte.

\paragraph{Théorème} Soit $n\geq 1$ un entier naturel. Alors l'application $n$ fois
\begin{eqnarray*}
  det: M_{n\times 1}(\R) \times M_{n\times 1}(\R) \times \ldots \times M_{n\times 1}(\R) &\rightarrow& \R \\
  (C_1, C_2, \ldots, C_n) &\mapsto& det(C_1, C_2, \ldots, C_n)
\end{eqnarray*}
posséde les propriétés suivantes
\begin{enumerate}
  \item Pour tout $j \in \{1; \ldots; n \}$, pour tous $C_1, \ldots, C_j, C_j', \ldots, C_n \in M_{n\times 1}(\R)$
    \begin{eqnarray*}
      det(C_1, \ldots, C_j + C_j', \ldots, C_n) =& det(C_1, \ldots, C_j, \ldots, C_n) \\
        &+ det(C_1, \ldots, C_j', \ldots, C_n)
    \end{eqnarray*}
    
  \item Pour tout $j \in \{1; \ldots; n\}$, pour tous $C_1, C_2, \ldots, C_n \in M_{n\times 1}(\R)$, pour tout $\lambda \in \R$
    $$det(C_1, \ldots, \lambda C_j, \ldots, C_n) = \lambda \cdot det(C_1, \ldots, C_j, \ldots, C_n)$$
    
  \item Pour tous $C_1, C_2, \ldots, C_n \in M_{n\times 1}(\R)$, pour tous $i, j \in \{1; \ldots; n\}, i \neq j$, si $C_i = C_j$, alors
    $$det(C_1, \ldots, C_i, \ldots, C_j(=C_i), \ldots, C_n) = 0$$
\end{enumerate}

\paragraph{Démonstration} 
\begin{enumerate}
  \item On a
    $$det(C_1, \ldots, C_j + C_j', \ldots, C_n) = \sum_{\sigma \in S_n} p_\sigma(C_1, \ldots, C_j + C_j' , \ldots, C_n)$$
    où
    $$ p_{\sigma}(C_1, \ldots, C_j + C_j', \ldots, C_n) = \epsilon(\sigma) \cdot c_{\sigma(1) 1} \cdot \ldots \cdot (c_{\sigma(j) j} + c_{\sigma(j) j}') \cdot \ldots \cdot c_{\sigma(n) n}$$
    $\Rightarrow$ distributivité de $\circ$ par rapport à $+$
   
  \item On a
    $$det(C_1, \ldots, \lambda C_j', \ldots, C_n) = \sum_{\sigma \in S_n} p_\sigma(C_1, \ldots, \lambda C_j' , \ldots, C_n)$$
    où
    $$ p_{\sigma}(C_1, \ldots, \lambda C_j', \ldots, C_n) = \epsilon(\sigma) \cdot c_{\sigma(1) 1} \cdot \ldots \cdot \lambda \cdot c_{\sigma(j) j}  \cdot \ldots \cdot c_{\sigma(n) n}$$

  \item Soit $\tau = (i ~ j) \in S_n$. On regroupe les permutations de $S_n$ par paires comme suit: Chaque $\sigma \in S_n$ avec $\sigma \circ \tau \in S_n$ \\
    On a: si $\sigma = \sigma \circ \tau$ on aurait
    \begin{eqnarray*}
      id = \sigma^{-1} \circ \sigma &=& \sigma^{-1} \circ (\sigma \circ \tau) \\
        &=& (\sigma^{-1} \circ \sigma) \circ \tau \\
        &=& id \circ \tau = \tau \rightarrow\text{ impossibru}
    \end{eqnarray*}
    donc $\sigma \neq \sigma \circ \tau$. On a
    \begin{eqnarray*}
      (\sigma \circ \tau) \circ \tau &=& \sigma \circ (\tau \circ \tau) \\
        &=& \sigma \circ (id) \\
        &=& \sigma 
    \end{eqnarray*}
    %
    On obtien aisni $\frac{n!}{2}$ paires de la forme $\{\sigma; \sigma  \circ \tau\}$. Dans chaque de ces paires on sélectionne une permutation $\sigma_n$ tout, on a donc sélectioné $\frac{n!}{2}$ permutations $\sigma_1, \sigma_2, \ldots, \sigma_{\frac{n!}{2}}$. On a donc
    $$S_n = \{ \sigma_1; \sigma_1 \circ \tau; \sigma_2; \sigma_2 \circ \tau; \ldots; \sigma_{\frac{n!}{2}}; \sigma_{\frac{n!}{2}} \circ \tau \}$$
    On obtient 
    \begin{eqnarray*}
      det(C_1, C_2, \ldots, C_n) &=& \sum_{\sigma \in S_n} p_{\sigma}(C_1, C_2, \ldots, C_n) \\
       &=& \sum_{i=1}^{\frac{n!}{2}} p_{\sigma_i}(C_1, C_2, \ldots, C_n) + p_{\sigma_i \circ \tau}(C_1, C_2, \ldots, C_n)
    \end{eqnarray*}
    %
    Montrons que pour tout $\sigma \in S_n$, on a
    $$p_{\sigma \circ \tau}(C_1, C_2, \ldots, C_n) = -p_{\sigma}(C_1, C_2, \ldots, C_n)$$
    Soit $\sigma \in S_n$. On a 
    $$p_{\sigma \circ \tau}(C_1, C_2, \ldots, C_n) = \epsilon(\sigma \circ \tau) \cdot a_{(\sigma \circ\tau)(1) 1} \cdot a_{(\sigma \circ\tau)(2) 2} \cdot \ldots \cdot a_{(\sigma \circ\tau)(n) n}$$
    Soit $k \in \{1; \ldots; n\}$
    \begin{itemize}
      \item si $k\notin \{i; j\}$, alors $\tau(k) = k$. Par suite 
        $$a_{(\sigma \circ \tau)(k) k} = a_{\sigma(k) k}$$
      
      \item si $k = i$, alors $\tau(k) = j$. Par suite $a_{(\sigma \circ \tau)(k) k} = a_{\sigma(j) i}$. Puisque $C_i = C_j$ on a $a_{\sigma(j) i} = a_{\sigma(j) j}$. On a donc
        $$a_{(\sigma \circ \tau)(k) k} = a_{(\sigma \circ \tau)(i) i} = a_{\sigma(j) j}$$
        
      \item si $k = j$, alors $\tau(k) = i$. Par suite $a_{(\sigma \circ \tau)(k) k} = a_{\sigma(i) j}$. Puisque $C_j = C_i$ on a $a_{\sigma(i) j} = a_{\sigma(i) i}$. On a donc
        $$a_{(\sigma \circ \tau)(k) k} = a_{(\sigma \circ \tau)(j) j} = a_{\sigma(i) i}$$
    \end{itemize}
    On a donc
    \begin{eqnarray*}
      a_{(\sigma \circ \tau)(1) 1} \cdot \ldots \cdot a_{(\sigma \circ \tau)(i) i} \cdot \ldots \cdot a_{(\sigma \circ \tau)(j) j} \cdot \ldots \cdot a_{(\sigma \circ \tau)(n) n} \\
        = a_{\sigma(1) 1} \cdot \ldots \cdot a_{\sigma(j) j} \cdot \ldots \cdot a_{\sigma(i) i} \cdot \ldots \cdot a_{\sigma(n) n} \\
        = a_{\sigma(1) 1} \cdot \ldots \cdot a_{\sigma(i) i} \cdot \ldots \cdot a_{\sigma(j) j} \cdot \ldots \cdot a_{\sigma(n) n} \\
    \end{eqnarray*}
    %
    De plus $\epsilon(\sigma \circ \tau) = \epsilon(\sigma) \cdot \epsilon(\tau)$ où on a $\epsilon(\tau) = -1$, donc
    $$\epsilon(\sigma \circ \tau) = -\epsilon(\sigma)$$
    Par conéquent 
    $$p_{\sigma \circ \tau}(C_1, C_2, \ldots, C_n) = -p_{\sigma}(C_1, C_2, \ldots, C_n)$$
    Ainsi pour tout $i\in \{1; \ldots; \frac{n!}{2}\}$
    \begin{eqnarray*}
      p_{\sigma_i \circ \tau}(C_1, C_2, \ldots, C_n) &=& -p_{\sigma_i}(C_1, C_2, \ldots, C_n) \\
      p_{\sigma_i \circ \tau}(C_1, C_2, \ldots, C_n) &+& p_{\sigma_i}(C_1, C_2, \ldots, C_n) ~=~ 0
    \end{eqnarray*}
    Il s'ensuit que $det(C_1, \ldots, C_i, \ldots, C_j(=C_i), \ldots, C_n) = 0$
\end{enumerate}

\paragraph{Corollaire} Soient $i, j \in \{1; \ldots; n\}$, $i\neq j$ et $C_1, C_2, \ldots, C_n$ $n$ matrices colonnes £ $n$ lignes. Alors
$$det(C_1, \ldots, C_i, \ldots, C_j, \ldots, C_n) = -det(C_1, \ldots, C_j, \ldots, C_i, \ldots, C_n)$$

\paragraph{Démonstration} On a
\begin{eqnarray*}
  0 =& det(C_1, \ldots, C_i+C_j, \ldots, C_i+C_j, \ldots, C_n) \\
    =& det(C_1, \ldots, C_i, \ldots, C_i+C_j, \ldots, C_n) \\
    &+ det(C_1, \ldots, C_j, \ldots, C_i+C_j, \ldots, C_n) \\
    =& det(C_1, \ldots, C_i, \ldots, C_i, \ldots, C_n) \\
    &+ det(C_1, \ldots, C_i, \ldots, C_j, \ldots, C_n) \\
    &+ det(C_1, \ldots, C_j, \ldots, C_i, \ldots, C_n) \\
    &+ det(C_1, \ldots, C_j, \ldots, C_j, \ldots, C_n) \\
    =& 0 \\
    &+ det(C_1, \ldots, C_i, \ldots, C_j, \ldots, C_n) \\
    &+ det(C_1, \ldots, C_j, \ldots, C_i, \ldots, C_n) \\
    &+ 0 \\
    =& det(C_1, \ldots, C_i, \ldots, C_j, \ldots, C_n) + det(C_1, \ldots, C_j, \ldots, C_i, \ldots, C_n) = 0
\end{eqnarray*}
On dit alors que l'application 
$$det: M_{n \times 1}(\R) \times \ldots \times M_{n\times 1}(\R) \rightarrow \R$$
est antisymétrique.

\paragraph{Théorème} Soit $A =(a_{ij})$ une matrice carrée de taille $n\times n$. Alors
$$det(A^{T}) = det(A)$$

\paragraph{Démonstration} On observe que l'application
\begin{eqnarray*}
  S_n &\rightarrow& S_n \\
  \sigma &\mapsto& \sigma^{-1}
\end{eqnarray*}
est bijective (elle est sa propre bijection réciproque). Il vient
\begin{eqnarray*}
  det(A^{T}) &=& \sum_{\sigma \in S_n} p_{\sigma}(A^{T}) \\
    &=& \sum_{\sigma^{-1} \in S_n} p_{\sigma^{-1}}(A^{T})
\end{eqnarray*}
Soit $\sigma \in S_n$
$$p_{\sigma^{-1}}(A^{T}) = \epsilon(\sigma^{-1}) \cdot (A^{T})_{\sigma^{-1}(1) 1} \cdot \ldots \cdot (A^{T})_{\sigma^{-1}(n) n}$$
On a $\epsilon(\sigma) \epsilon(\sigma^{-1}) = \epsilon(\sigma \circ \sigma^{-1}) = \epsilon(id) = 1$. Puisque $\epsilon(\sigma) \pm 1$ et $\epsilon(\sigma^{-1}) \pm 1$, on a 
$$\epsilon(\sigma) = \epsilon(\sigma^{-1})$$
Maintenant
$$(A^{T})_{\sigma^{-1}(1) 1} \cdot \ldots \cdot (A^{T})_{\sigma^{-1}(n) n} = A_{1 \sigma^{-1}(1)} \cdot \ldots \cdot A_{n \sigma^{-1}(n)}$$
Comme $\sigma^{-1}: \{1; \ldots; n\} \rightarrow \{1; \ldots; n\}$ est bijective on a
\begin{eqnarray*}
  A_{1 \sigma^{-1}(1)} \cdot \ldots \cdot A_{n \sigma^{-1}(n)} &=& \prod_{j=1}^n A_{j \sigma^{-1}(j)} \\
    &=& \prod_{k=1}^n A_{\sigma(k) k} ~~ (\text{on a posé } k = \sigma^{-1}(j))
\end{eqnarray*}
Donc $p_{\sigma^{-1}}(A^{T}) = p_{\sigma}(A)$. Par suite
$$det(A^{T}) = \sum_{\sigma \in S_n} p_{\sigma}(A) = det(A)$$

\paragraph{Lemme} Soit $\sigma \in S_n$ telle que pour tout $i \in \{1; \ldots; n\}$, $\sigma(i) \leq i$. Alors $\sigma  = id$. En effet on a
\begin{itemize}
  \item $1 \leq \sigma(1) \leq 1$ (par hypothèse), donc $\sigma(1) = 1$.
  \item on a $\sigma(2) \neq \sigma(1) = 1$, donc $\sigma(2) \geq 2$, et par hypothèse $\sigma(2) \leq 2$. Par suite $\sigma(2) = 2$.
  \item Ainsi de suite.
\end{itemize}
Il est équivalent de dire que si une permutations $\sigma \in S_n$ est différendte de $id$, alors il existe $i \in \{1; \ldots; n\}$ tel que $\sigma(i) > i$.

\paragraph{Théorème} Le déterminant d'une matrice carré triangulaire supérieure (resp. triangulaire inférieure) est àgal au produit des ses coefficients diagonaux.

\paragraph{Démonstration}  Soit $A = (a_ij)$ une matrice carrée de taille $n \times n$ triangulaire supérieure. Il vient 
$$det(A) = p_{id}(A) + \sum_{\sigma \in S_n, \sigma \neq id} p_{\sigma}(A)$$
Si $\sigma \neq id$, alors, d'après le lemme, il existe $j \in \{1; \ldots; n \}$ tel que $\sigma(j) > j$. Puisque $A$ est triangulaire supérieure, $a_{\sigma(j) j} = 0$. Par suite $p_{\sigma}(A) = 0$ et donc 
$$\sum_{\sigma \in S_n, \sigma \neq id} p_{\sigma}(A) = 0$$
Il reste
$$det(A) = p_{id}(A) = a_{11} \cdot a_{22} \cdot \ldots \cdot a_{nn}$$
Le cas "triangulaire inférieure" se déduit du cas "triangulaire supérieure" par transposition.

%
\subsection{Le déterminant sous l'effet des opérations élémentaires}
%
Les résultats précédents indiquent comment se comporte le déterminant sous l'effet des opörations élémentaires sur les lignes d'une matrice:
\begin{itemize}
  \item Le déterminant ne change pa si on ajout à une ligne un multiple d'une autre ligne
    $$\begin{vmatrix} L_1 \\ L_2 + 4 L_3 \\ L_3 \end{vmatrix} 
      = \begin{vmatrix} L_1 \\ L_2 \\ L_3 \end{vmatrix} + 4 \cdot \begin{vmatrix} L_1 \\ L_3 \\ L_3 \end{vmatrix}
      = \begin{vmatrix} L_1 \\ L_2 \\ L_3 \end{vmatrix} + 0
      = \begin{vmatrix} L_1 \\ L_2 \\ L_3 \end{vmatrix}$$
      
  \item Lorsque on multiplie une ligne par un réel, le déterminant est multiplié par ce réel
    $$\begin{vmatrix} 5 L_1 \\ L_2 \\ L_3 \end{vmatrix} = 5 \cdot \begin{vmatrix} L_1 \\ L_2 \\ L_3 \end{vmatrix}$$
    
  \item Lorsque on permute deux lignes, le déterminant est multiplié par $-1$
    $$\begin{vmatrix} L_1 \\ L_3 \\ L_2 \end{vmatrix} = -1 \cdot \begin{vmatrix} L_1 \\ L_2 \\ L_3 \end{vmatrix}$$
\end{itemize}

\paragraph{Remarque} Le deux premières propriétés découlent de la multilinéarité du détérminant.

\paragraph{} On peut donc calculre un déterminant un utilisant l'algorithme d'élimination de Gauss. Par des opérations élémentaires sur les lignes ou sur les colonnes, on met la matrice sous la forme triangulaire. On applique à chaque étape les régles du calcul du déterminant. Le déterminant est alors égal au produit des coefficients diagonaux de cette matrice triangulaire.

%
%
\section{Inversibilité des matrices et déterminant}
%
%
\paragraph{Théorème} Soient $A$ et $B$ deux matrices carrées de même taille. Alors 
$$det(A B) = det(A) \cdot det(B)$$

\paragraph{Démonstration} Nous nous contentans ici de montros cette formule dasn le cas de matrices de taille $3 \times 3$, le cas général se traite de façon analogue. \\
Soient $A$ et $B$ deux matrices de taille $3 \times 3$. On note $C_1, C_2, C_3$ les colonnes de $A$
$$A = (C_1, C_2, C_3) \text{ et } B=(b_{ij})_{1 \leq i, j \leq n}$$
On observe que
$$A B = \left(
  A \begin{pmatrix} b_{11} \\ b_{21} \\ b_{31} \end{pmatrix} ~ 
  A \begin{pmatrix} b_{12} \\ b_{22} \\ b_{32} \end{pmatrix} ~ 
  A \begin{pmatrix} b_{13} \\ b_{23} \\ b_{33} \end{pmatrix}
\right)$$
Pour $i \in \{1; 2; 3\}$, on a également
\begin{eqnarray*}
  A \begin{pmatrix} b_{1i} \\ b_{2i} \\ b_{3i} \end{pmatrix}
  &=& A \left( b_{1i} \begin{pmatrix} 1 \\ 0 \\ 0 \end{pmatrix} + b_{2i} \begin{pmatrix} 0 \\ 1 \\ 0 \end{pmatrix} + b_{3i} \begin{pmatrix} 0 \\ 0 \\ 1 \end{pmatrix} \right) \\
    &=& b_{1i} A \begin{pmatrix} 1 \\ 0 \\ 0 \end{pmatrix} + b_{2i} A \begin{pmatrix} 0 \\ 1 \\ 0 \end{pmatrix} + b_{3i} A \begin{pmatrix} 0 \\ 0 \\ 1 \end{pmatrix} \\
    &=& b_{1i} C_1 + b_{2i} C_2 + b_{3i} C_3
\end{eqnarray*}
Il vient
$$det(A B) = \begin{vmatrix} \\ b_{11} C_1 + b_{21} C_2 + b_{31} C_3 + b_{12} C_1 + b_{22} C_2 + b_{32} C_3 + b_{13} C_1 + b_{23} C_2 + b_{33} C_3 \\ \\ \end{vmatrix}$$
On dévelippe ce déterminant par multilinéairté. On obtient $3^3 = 27$ termes. Deux sortes de termes:
\begin{itemize}
  \item Ceux qui correspondent au choix d'une permutations $\sigma \in S_3$ des colonnes $C_1, C_2, C_3$:
    $$b_{\sigma(1) 1} \cdot b_{\sigma(2) 2} \cdot b_{\sigma(3) 3} \cdot \begin{vmatrix} C_{\sigma(1)} & C_{\sigma(2)} & C_{\sigma(3)} \end{vmatrix}$$
    
  \item Les autres pour lesquels au moins deux retenues sur les trois sont égales. Alors le déterminant correspondant est nul, et donc le terme lui-même est nul.
\end{itemize}
On obtient donc
$$det(A B) = \sum_{\sigma \in S_3} b_{\sigma(1) 1} \cdot b_{\sigma(2) 2} \cdot b_{\sigma(3) 3} \cdot \begin{vmatrix} C_{\sigma(1)} & C_{\sigma(2)} & C_{\sigma(3)} \end{vmatrix}$$
où pour tout $\sigma \in S_3$,
\begin{eqnarray*}
  \begin{vmatrix} C_{\sigma(1)} & C_{\sigma(2)} & C_{\sigma(3)} \end{vmatrix}
  &=& \epsilon(\sigma) \begin{vmatrix} C_1 & C_2 & C_ 3 \end{vmatrix} \\
    &=& \epsilon(\sigma) \cdot det(A)
\end{eqnarray*}
D'où
\begin{eqnarray*}
  det(A B) &=& \sum_{\sigma \in S_3} \epsilon(\sigma) \cdot b_{\sigma(1) 1} \cdot b_{\sigma(2) 2} \cdot b_{\sigma(3) 3} \cdot det(A) \\
    &=& det(A) \left( \sum_{\sigma \in S_3} \epsilon(\sigma) \cdot b_{\sigma(1) 1} \cdot b_{\sigma(2) 2} \cdot b_{\sigma(3) 3} \right) \\
    &=& det(A) \cdot det(B)
\end{eqnarray*}

\paragraph{Théorème} Soit $A$ une matrice carrée de taille $n \times n$, alors 
$$A \text{ est inversible } \Leftrightarrow det(A) \neq 0$$

\paragraph{Démonstration} 
\begin{itemize}
  \item [$\Rightarrow$] Supposons que $A$ est inversible. On a donc
    $$A A^{-1} = I_n$$
    Il vient
    $$det(A) \cdot det(A^{-1}) = det(AA^{-1}) = det(I_n) = 1 \neq 0$$
    Cela implqiue que $det(A) \neq 0$
  
  \item [$\Leftarrow$] Réciproquement, montrons que si $A$ n'est pas inversible, alors $det(A) = 0$. Supposons docn que $A$ ne soit pas inversible. Considérons le système 
    $$A \cdot X = 0$$
    Puisque $A$ n'est pas inversible et que $0$ est solution de cesystème, ce système admet une infinité de solutions. Il existe donc des réels $\alpha_1, \ldots, \alpha_n$ non tous nuls tels que
    $$A \begin{pmatrix} \alpha_1 \\ \vdots \\ \alpha_n \end{pmatrix} = 0$$
    Soient $C_1, \ldots, C_n$ les colonnes de $A$. On a 
    $$0 = A \begin{pmatrix} \alpha_1 \\ \vdots \\ \alpha_n \end{pmatrix} = \alpha_1 \cdot C_1 + \ldots + \alpha_n \cdot C_n$$
    Soit $i_0 \in \{1; \ldots; n \}$ tel que $\alpha_{i_0} \neq 0$. On obtient 
    $$C_{i_0} = - \sum_{i=1, i\neq i_0}^n \frac{\alpha_i}{\alpha_{i_0}} C_i$$
    Cela entraîne que
    \begin{eqnarray*}
      det(A) &=& \begin{vmatrix} \\
        C_1 & \ldots & C_{i_0} & \ldots & C_i & \ldots & C_n 
      \\ \\ \end{vmatrix} \\
        &=& \begin{vmatrix} \\
          C_1 & \ldots & - \sum_{i=1, i\neq i_0}^n \frac{\alpha_i}{\alpha_{i_0}} C_i & \ldots & C_i & \ldots & C_n 
        \\ \\\end{vmatrix} \\
        &=& - \sum_{i=1, i\neq i_0}^n \frac{\alpha_i}{\alpha_{i_0}} \begin{vmatrix} \\
          C_1 & \ldots & C_{i} & \ldots & C_i & \ldots & C_n 
        \\ \\ \end{vmatrix}
    \end{eqnarray*}
    Dans le $i^{ème}$ terme de cette somme la colonne $C_i$ apparaît en position $i$ et $i_0$ donc
    $$\begin{vmatrix} \\ C_1 & \ldots & C_{i_0} & \ldots & C_i & \ldots & C_n \\ \\ \end{vmatrix} = 0$$
    Par suite
    $$det(A) = 0$$
\end{itemize}

%
\subsection{Cofacteur d'une matrice}
%
\paragraph{Définition} Soit $A = (a_{ij})$ une matrice carrée de taille $n\times n$. Soit $(i ~ j) \in \{1; \ldots; n\} \times \{1; \ldots; n \}$. On appelle cofacteur de $A$ associé à $(i ~ j)$ le nombre réel défini par
$$A_{ij} = (-1)^{i+j} \begin{vmatrix}
  a_{11} & \ldots & a_{1 j-1} & a_{1 j+1} & \ldots & a_{1n} \\
  \vdots &  & \vdots & \vdots &  & \vdots \\
  a_{i-1 1} & \ldots & a_{i-1 j-1} & a_{i-1 j+1} & \ldots & a_{i-1 n} \\
  a_{i+1 1} & \ldots & a_{i+1 j-1} & a_{i+1 j+1} & \ldots & a_{i+1 n} \\
  \vdots &  & \vdots & \vdots &  & \vdots \\
  a_{n 1} & \ldots & a_{n j-1} & a_{n j+1} & \ldots & a_{nn}
\end{vmatrix}$$
Ce déterminant (de matrice de taille $(n-1) \times (n-1)$) est obtenu à partir de celui de $A$ en supprimant le $i^{ème}$ ligne et la $j^{ème}$ colonne.

\paragraph{Théorème} Soit $A$ une matrice carrée de taille $n\times n$. Soit $j \in \{1; \ldots; n\}$. Alors
$$det(A) = \sum_{i=1}^{n} a_{ij} A_{ij}$$
On dit que l'on développe $det(A)$ par rapport à la $j^{ème}$ colonne.
  
